{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paragraphs = sc.newAPIHadoopFile('../shakespeare.txt', \"org.apache.hadoop.mapreduce.lib.input.TextInputFormat\",\"org.apache.hadoop.io.LongWritable\", \"org.apache.hadoop.io.Text\",     conf={\"textinputformat.record.delimiter\": '\\n\\n'}).map(lambda l:l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanParagraphs = paragraphs.map(lambda paragraph: re.sub('[^a-zA-Z0-9 ]','',paragraph.lower().strip()))\n",
    "cleanParagraphs = cleanParagraphs.map(lambda paragraph: re.sub('[ ]+',' ',paragraph))\n",
    "cleanParagraphs = cleanParagraphs.filter(lambda l: l!=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histog = cleanParagraphs.map(lambda e: Counter(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({u'0': 1, u'1': 1, u'6': 1, u'9': 1}),\n",
       " Counter({u' ': 1, u'e': 2, u'h': 1, u'n': 2, u'o': 1, u's': 2, u't': 2})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histog.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En vez de utilizar palabras va a hashearlas, esto es, representarlas por un número.\n",
    "HashingTF convierte cada palabra en un hash con un un máximo de 2^20\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "flatmap -> hago un map y lo aplano, pasando de ser una lista de listas a un vector simple.\n",
    "es como el unlist de R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WordInDoc = cleanParagraphs.flatMap(lambda p: p.split(\" \")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordInDoc = WordInDoc.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordInDoc = wordInDoc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29134"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordInDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inicializar proceso de clálculo\n",
    "hasingTF = HashingTF(wordInDoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TF - cálculo\n",
    "tf = hasingTF.transform(cleanParagraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(29134, {7489: 1.0, 8425: 1.0, 22210: 1.0, 23458: 1.0}),\n",
       " SparseVector(29134, {1188: 2.0, 2748: 1.0, 3372: 2.0, 4993: 1.0, 16225: 1.0, 17161: 2.0, 18097: 2.0})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No salen términos porque está haciendo un hashing, salen números en vez de palabras...\n",
    "tf.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#No funciona muy bien el hasingTF. Pero es bastante bueno."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "La implementación produce colisiones -> 2 palabras con el mismo número.\n",
    "Los números a veces no los hashea bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasingTF.indexOf('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016-03-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WordInDoc = cleanParagraphs.flatMap(lambda p: p.split(' ')).distinct().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(WordInDoc.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = hashingTF.transform(cleanParagraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[17] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashingTF.indexOf('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sparse -> solo guarda los elementos que son distintos de cero su número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashingTF.indexOf(\"a\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tiene el problema de que si introduces una palabra nueva, no aumenta el tamaño del hashing, sino que incorpora la\n",
    "palabra reemplazando alguna de las existentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDF\n",
    "Inverse document frequency<br>Número de documentos inverso en el que aparece mi palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idf = (IDF(minDocFreq=2).fit(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = idf.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(29134, {7489: 4.9538, 8425: 4.7174, 22210: 3.4926, 23458: 4.8286}),\n",
       " SparseVector(29134, {1188: 0.0221, 2748: 0.1816, 3372: 0.2467, 4993: 0.0095, 16225: 0.2596, 17161: 0.045, 18097: 0.0974}),\n",
       " SparseVector(29134, {564: 0.2944, 1188: 0.0331, 1812: 0.3285, 2124: 0.6756, 2436: 0.3948, 3372: 0.2467, 3996: 0.5264, 4308: 0.5906, 4993: 0.0189, 15289: 0.5161, 16225: 0.2596, 16849: 0.4957, 17473: 0.4594, 17785: 0.066}),\n",
       " SparseVector(29134, {564: 2.9436, 876: 2.3565, 1188: 0.7506, 1500: 5.7934, 1812: 4.7637, 2124: 1.3512, 2436: 4.3426, 2748: 4.54, 3372: 3.7004, 3684: 6.2238, 3996: 6.317, 4308: 8.2677, 4993: 1.0021, 15289: 6.7095, 15601: 5.5198, 15913: 5.5709, 16225: 8.8261, 16849: 4.4617, 17161: 0.6531, 17473: 1.3783, 17785: 2.1764, 18097: 2.8235, 18409: 1.2959, 22210: 3.4926}),\n",
       " SparseVector(29134, {564: 3.1399, 876: 2.3565, 1188: 0.7616, 1500: 2.8967, 1812: 4.4351, 2124: 2.0267, 2436: 4.3426, 2748: 5.0848, 3372: 4.5638, 3684: 6.956, 3996: 10.002, 4308: 12.4016, 4993: 1.0871, 7801: 4.1257, 15289: 5.6773, 15601: 6.6238, 15913: 4.558, 16225: 8.8261, 16849: 6.6925, 17161: 0.6305, 17473: 2.7566, 17785: 1.5828, 18097: 1.9959, 18409: 1.9438, 18721: 1.1442, 19033: 2.0809})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.take(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "La magnitud de cada término es directamente proporcional con su importancia en el documento.\n",
    "Para implementarlo en paralelo o distribuido spark trabaja de forma particular."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tfidf.zipWithIndex\n",
    "\n",
    "parrafo 1, indice 0\n",
    "parrafo 2, indice 1\n",
    "parrafo 2, indice 2\n",
    "\n",
    "Permite acceder a cada elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tfidf_bak = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(SparseVector(29134, {7489: 4.9538, 8425: 4.7174, 22210: 3.4926, 23458: 4.8286}),\n",
       "  0),\n",
       " (SparseVector(29134, {1188: 0.0221, 2748: 0.1816, 3372: 0.2467, 4993: 0.0095, 16225: 0.2596, 17161: 0.045, 18097: 0.0974}),\n",
       "  1),\n",
       " (SparseVector(29134, {564: 0.2944, 1188: 0.0331, 1812: 0.3285, 2124: 0.6756, 2436: 0.3948, 3372: 0.2467, 3996: 0.5264, 4308: 0.5906, 4993: 0.0189, 15289: 0.5161, 16225: 0.2596, 16849: 0.4957, 17473: 0.4594, 17785: 0.066}),\n",
       "  2),\n",
       " (SparseVector(29134, {564: 2.9436, 876: 2.3565, 1188: 0.7506, 1500: 5.7934, 1812: 4.7637, 2124: 1.3512, 2436: 4.3426, 2748: 4.54, 3372: 3.7004, 3684: 6.2238, 3996: 6.317, 4308: 8.2677, 4993: 1.0021, 15289: 6.7095, 15601: 5.5198, 15913: 5.5709, 16225: 8.8261, 16849: 4.4617, 17161: 0.6531, 17473: 1.3783, 17785: 2.1764, 18097: 2.8235, 18409: 1.2959, 22210: 3.4926}),\n",
       "  3),\n",
       " (SparseVector(29134, {564: 3.1399, 876: 2.3565, 1188: 0.7616, 1500: 2.8967, 1812: 4.4351, 2124: 2.0267, 2436: 4.3426, 2748: 5.0848, 3372: 4.5638, 3684: 6.956, 3996: 10.002, 4308: 12.4016, 4993: 1.0871, 7801: 4.1257, 15289: 5.6773, 15601: 6.6238, 15913: 4.558, 16225: 8.8261, 16849: 6.6925, 17161: 0.6305, 17473: 2.7566, 17785: 1.5828, 18097: 1.9959, 18409: 1.9438, 18721: 1.1442, 19033: 2.0809}),\n",
       "  4)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos a añadir un elemento para crear una tupla donde aparezca el índice que corresponde a cada documento.\n",
    "tfidf = tfidf_bak \n",
    "tfidf = tfidf.zipWithIndex()\n",
    "tfidf.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  SparseVector(29134, {7489: 4.9538, 8425: 4.7174, 22210: 3.4926, 23458: 4.8286})),\n",
       " (1,\n",
       "  SparseVector(29134, {1188: 0.0221, 2748: 0.1816, 3372: 0.2467, 4993: 0.0095, 16225: 0.2596, 17161: 0.045, 18097: 0.0974})),\n",
       " (2,\n",
       "  SparseVector(29134, {564: 0.2944, 1188: 0.0331, 1812: 0.3285, 2124: 0.6756, 2436: 0.3948, 3372: 0.2467, 3996: 0.5264, 4308: 0.5906, 4993: 0.0189, 15289: 0.5161, 16225: 0.2596, 16849: 0.4957, 17473: 0.4594, 17785: 0.066})),\n",
       " (3,\n",
       "  SparseVector(29134, {564: 2.9436, 876: 2.3565, 1188: 0.7506, 1500: 5.7934, 1812: 4.7637, 2124: 1.3512, 2436: 4.3426, 2748: 4.54, 3372: 3.7004, 3684: 6.2238, 3996: 6.317, 4308: 8.2677, 4993: 1.0021, 15289: 6.7095, 15601: 5.5198, 15913: 5.5709, 16225: 8.8261, 16849: 4.4617, 17161: 0.6531, 17473: 1.3783, 17785: 2.1764, 18097: 2.8235, 18409: 1.2959, 22210: 3.4926}))]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos a hacer un map para cambiar la posición y hacer que la tupla tenga índice - documento.b\n",
    "tfidf = tfidf.map(lambda(doc,idx): (idx,doc)).cache()\n",
    "tfidf.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_SparseVector(vec):\n",
    "    llaves = vec.indices\n",
    "    valores = vec.values\n",
    "    llave_valor = zip(llaves,valores)\n",
    "    return dict(llave_valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tfidf_bak2 = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[64] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = tfidf.map(lambda (i,v): (i,change_SparseVector(v))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  {7489: 4.953790556544952,\n",
       "   8425: 4.7174017784807214,\n",
       "   22210: 3.4925948872519434,\n",
       "   23458: 4.8286274135909455}),\n",
       " (1,\n",
       "  {1188: 0.022075279303240627,\n",
       "   2748: 0.18160047451230643,\n",
       "   3372: 0.24669151646739343,\n",
       "   4993: 0.0094533554165712342,\n",
       "   16225: 0.25959250951993185,\n",
       "   17161: 0.045038376402269438,\n",
       "   18097: 0.097360801419155082})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RESET:\n",
    "from pyspark.mllib.feature import IDF\n",
    "idf = (IDF(minDocFreq=2).fit(tf))\n",
    "tfidf = idf.transform(tf)\n",
    "tfidf = tfidf.zipWithIndex()\n",
    "tfidf = tfidf.map(lambda(doc,idx): (idx,doc)).cache()\n",
    "\n",
    "def change_SparseVector(vec):\n",
    "    llaves = vec.indices\n",
    "    valores = vec.values\n",
    "    llave_valor = zip(llaves,valores)\n",
    "    return dict(llave_valor)\n",
    "    \n",
    "tfidf = tfidf.map(lambda (i,v): (i,change_SparseVector(v))).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos ahora a hacer consultas contra nuestra variable sparse tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = [1245,10978]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tfidf_bak3 = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tifidf = tfidf_bak3\n",
    "\n",
    "#Esta es la idea --> tfidf.map(lambda(idx,dic): devuelveme_query(query,dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Devuelve el peso acumulado.\n",
    "\n",
    "def devuelveme_query (query,dicD):\n",
    "    summ = 0\n",
    "    for q in query:\n",
    "        if q in dicD:\n",
    "            summ += dicD[q]\n",
    "            \n",
    "    return summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_bak4= tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = tfidf_bak4\n",
    "tfidf = tfidf.map(lambda (idD,dicD): (idD,devuelveme_query(query,dicD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (1, 0)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.take(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
